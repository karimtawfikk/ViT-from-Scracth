# ViT-from-Scracth

This project is a replica of the Hugging Face Vision Transformer (ViT) architecture with approximately 86 million parameters, applied to a fine-grained fruit classification task. Trained on a curated dataset of fruit varieties, the model achieved 92% accuracy.
